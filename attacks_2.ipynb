{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "qibqhGvuxZCv",
      "metadata": {
        "id": "qibqhGvuxZCv"
      },
      "source": [
        "# FGSM vs model-based attacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4abfe971",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4abfe971",
        "outputId": "856b6ad4-924e-4035-89b1-2fc74d7520ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import math, os, random, json, numpy as np, pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)\n",
        "\n",
        "TRAIN_FILE = 'PowerCons_TRAIN.tsv'\n",
        "TEST_FILE  = 'PowerCons_TEST.tsv'\n",
        "SEQ_IN = 48\n",
        "SEQ_OUT = 12\n",
        "STEP = 1\n",
        "EPS = 0.03"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "179afbb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "179afbb8",
        "outputId": "8a1b0bd9-78c8-434d-efc0-13da61c96497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw shapes : (180, 145) (180, 145)\n",
            "Split shapes: (162, 145) (18, 145)\n"
          ]
        }
      ],
      "source": [
        "def load_tsv(path):\n",
        "    return pd.read_csv(path, sep='\\t', header=None).values.astype('float32')\n",
        "\n",
        "raw_train_full = load_tsv(TRAIN_FILE)\n",
        "raw_test  = load_tsv(TEST_FILE)\n",
        "print('Raw shapes :', raw_train_full.shape, raw_test.shape)\n",
        "\n",
        "# Нужна нормализация?\n",
        "mu = raw_train_full.mean(axis=1, keepdims=True)\n",
        "std = raw_train_full.std(axis=1, keepdims=True) + 1e-8\n",
        "raw_train_full = (raw_train_full - mu) / std\n",
        "raw_test = (raw_test - mu) / std\n",
        "\n",
        "VAL_FRAC = 0.1\n",
        "split = int(raw_train_full.shape[0] * (1 - VAL_FRAC))\n",
        "train_raw, val_raw = raw_train_full[:split], raw_train_full[split:]\n",
        "print('Split shapes:', train_raw.shape, val_raw.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebfdc12b",
      "metadata": {
        "id": "ebfdc12b"
      },
      "outputs": [],
      "source": [
        "def create_windows(arr, seq_in=SEQ_IN, seq_out=SEQ_OUT, step=STEP, thr=0.0):\n",
        "    \"\"\"Преобразует массивы в выборку для бинарной классификации.\n",
        "    y[t] = 1 если будущее значение > thr, иначе 0.\n",
        "    Возвращает TensorDataset(X, y).\"\"\"\n",
        "    X, y = [], []\n",
        "    for series in arr:\n",
        "        for i in range(0, len(series)-seq_in-seq_out+1, step):\n",
        "            X.append(series[i:i+seq_in, None])\n",
        "            target_slice = series[i+seq_in:i+seq_in+seq_out]\n",
        "            y.append( (target_slice > thr).astype('float32') )\n",
        "    X = torch.tensor(np.stack(X), dtype=torch.float32)\n",
        "    y = torch.tensor(np.stack(y), dtype=torch.float32)\n",
        "    return TensorDataset(X, y)\n",
        "\n",
        "train_ds = create_windows(train_raw)\n",
        "val_ds   = create_windows(val_raw)\n",
        "test_ds  = create_windows(raw_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=128)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f23c5eb",
      "metadata": {
        "id": "7f23c5eb"
      },
      "outputs": [],
      "source": [
        "class Activation(nn.Module):\n",
        "    def __init__(self, act='identity'):\n",
        "        super().__init__()\n",
        "        if act == 'sigmoid':\n",
        "            self.act = nn.Sigmoid()\n",
        "        elif act == 'tanh':\n",
        "            self.act = nn.Tanh()\n",
        "        else:\n",
        "            self.act = nn.Identity()\n",
        "    def forward(self, x): return self.act(x)\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_dim=64, n_layers=2, x_dim=1, output_dim=SEQ_OUT, dropout=0.2, activation_type='identity'):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.rnn = nn.LSTM(x_dim, hidden_dim, num_layers=n_layers, dropout=dropout if n_layers>1 else 0.0, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim * n_layers, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.final_activation = Activation(activation_type)\n",
        "\n",
        "    def forward(self, data):\n",
        "        _, (hidden, _) = self.rnn(data)\n",
        "        hidden = hidden.transpose(0,1).reshape(data.size(0), -1)\n",
        "        hidden = self.dropout(hidden)\n",
        "        out = self.relu(self.fc1(hidden))\n",
        "        out = self.fc2(self.dropout(out))\n",
        "        return self.final_activation(out)\n",
        "\n",
        "model = LSTM().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a99473a",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a99473a",
        "outputId": "3cafbed9-dc47-4327-b3ff-83b32df3ea60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E01 Train 0.6025 | Val 0.5322\n",
            "E02 Train 0.5376 | Val 0.5396\n",
            "E03 Train 0.5229 | Val 0.4966\n",
            "E04 Train 0.5165 | Val 0.5086\n",
            "E05 Train 0.5093 | Val 0.4755\n",
            "E06 Train 0.5073 | Val 0.4864\n",
            "E07 Train 0.5092 | Val 0.5703\n",
            "E08 Train 0.5062 | Val 0.4547\n",
            "E09 Train 0.5059 | Val 0.5173\n",
            "E10 Train 0.4996 | Val 0.4836\n",
            "E11 Train 0.4923 | Val 0.5386\n",
            "E12 Train 0.4884 | Val 0.4323\n",
            "E13 Train 0.4830 | Val 0.4933\n",
            "E14 Train 0.4771 | Val 0.5028\n",
            "E15 Train 0.4702 | Val 0.4435\n",
            "E16 Train 0.4694 | Val 0.4481\n",
            "E17 Train 0.4587 | Val 0.4387\n",
            "E18 Train 0.4532 | Val 0.4136\n",
            "E19 Train 0.4514 | Val 0.3658\n",
            "E20 Train 0.4455 | Val 0.3892\n",
            "E21 Train 0.4423 | Val 0.3957\n",
            "E22 Train 0.4432 | Val 0.5196\n",
            "E23 Train 0.4365 | Val 0.4355\n",
            "E24 Train 0.4297 | Val 0.4272\n",
            "E25 Train 0.4240 | Val 0.4562\n",
            "Early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    loss_sum, n = 0., 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            loss = F.binary_cross_entropy_with_logits(model(x), y)\n",
        "            loss_sum += loss.item()*x.size(0)\n",
        "            n += x.size(0)\n",
        "    return loss_sum / n\n",
        "\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3)\n",
        "\n",
        "best, patience, wait = 1e9, 6, 0\n",
        "for epoch in range(1, 51):\n",
        "    model.train()\n",
        "    run_loss, n = 0., 0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        opt.zero_grad()\n",
        "        loss = F.binary_cross_entropy_with_logits(model(x), y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        run_loss += loss.item()*x.size(0)\n",
        "        n += x.size(0)\n",
        "    val_loss = F.binary_cross_entropy_with_logits(model(x), y)\n",
        "    scheduler.step(val_loss)\n",
        "    print(f'E{epoch:02d} Train {run_loss/n:.4f} | Val {val_loss:.4f}')\n",
        "    if val_loss < best-1e-4:\n",
        "        best, wait = val_loss, 0\n",
        "        torch.save(model.state_dict(), 'victim_best.pth')\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print('Early stopping')\n",
        "            break\n",
        "model.load_state_dict(torch.load('victim_best.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8679d524",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8679d524"
      },
      "outputs": [],
      "source": [
        "class SurrogateNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv1d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*SEQ_IN, 256), nn.ReLU(),\n",
        "            nn.Linear(256, SEQ_IN),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1,2)\n",
        "        out = self.net(x)\n",
        "        return out.unsqueeze(-1)\n",
        "\n",
        "surrogate = SurrogateNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "618df1e4",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "618df1e4",
        "outputId": "d64b73a9-9923-443a-89b8-2b7a0e60a9a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Surr E01 victim‑loss 0.4903\n",
            "Surr E02 victim‑loss 0.4910\n",
            "Surr E03 victim‑loss 0.4919\n",
            "Surr E04 victim‑loss 0.4928\n",
            "Surr E05 victim‑loss 0.4937\n",
            "Surr E06 victim‑loss 0.4947\n",
            "Surr E07 victim‑loss 0.4958\n",
            "Surr E08 victim‑loss 0.4970\n",
            "Surr E09 victim‑loss 0.4981\n",
            "Surr E10 victim‑loss 0.4992\n",
            "Surr E11 victim‑loss 0.5007\n",
            "Surr E12 victim‑loss 0.5019\n",
            "Surr E13 victim‑loss 0.5034\n",
            "Surr E14 victim‑loss 0.5048\n",
            "Surr E15 victim‑loss 0.5062\n"
          ]
        }
      ],
      "source": [
        "for p in model.parameters():\n",
        "    p.requires_grad_(False)\n",
        "model.eval()\n",
        "\n",
        "def train_surrogate(surr, victim, loader, eps=EPS, epochs=15, lr=1e-4, alpha_l2=1e-3):\n",
        "    opt = torch.optim.Adam(surr.parameters(), lr)\n",
        "    for ep in range(1, epochs+1):\n",
        "        surr.train(); run_vloss = 0.\n",
        "        eps_curr = eps * (ep/epochs)\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            delta = eps_curr * torch.tanh(surr(x))\n",
        "            x_adv = torch.clamp(x + delta, -1, 1)\n",
        "            vloss = F.binary_cross_entropy_with_logits(victim(x_adv), y)\n",
        "            reg = alpha_l2 * (delta**2).mean()\n",
        "            loss = -(vloss - reg)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            run_vloss += vloss.item()*x.size(0)\n",
        "        print(f'Surr E{ep:02d} victim‑loss {run_vloss/len(loader.dataset):.4f}')\n",
        "    torch.save(surr.state_dict(), 'surrogate_maxloss.pth')\n",
        "\n",
        "train_surrogate(surrogate, model, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ead8d0",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "33ead8d0"
      },
      "outputs": [],
      "source": [
        "class Attack:\n",
        "    def __init__(self, eps, clamp=(-1,1)):\n",
        "        self.eps = eps\n",
        "        self.clamp = clamp\n",
        "\n",
        "class FGSMAttack(Attack):\n",
        "    def __call__(self, model, x, y):\n",
        "        x_req = x.clone().detach().requires_grad_(True)\n",
        "        loss = F.binary_cross_entropy_with_logits(model(x_req), y)\n",
        "        loss.backward()\n",
        "        delta = self.eps * x_req.grad.sign()\n",
        "        x_adv = torch.clamp(x + delta, *self.clamp)\n",
        "        return x_adv.detach()\n",
        "\n",
        "class ModelBasedAttack(Attack):\n",
        "\n",
        "    def __init__(self, surrogate, eps, clamp=(-1,1)):\n",
        "        super().__init__(eps, clamp)\n",
        "        self.surr = surrogate.eval()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(self, model, x, y):\n",
        "        delta = self.eps * torch.tanh(self.surr(x))\n",
        "        return torch.clamp(x + delta, *self.clamp)\n",
        "\n",
        "fgsm_attack  = FGSMAttack(EPS)\n",
        "model_attack = ModelBasedAttack(surrogate, EPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02b497ed",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "02b497ed",
        "outputId": "56323f4d-ed48-457d-a23c-ebe854feefaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fooling rate FGSM  : 0.514\n",
            "Fooling rate Model : 0.476\n"
          ]
        }
      ],
      "source": [
        "def preds_to_labels(logits):\n",
        "    return (torch.sigmoid(logits) >= 0.5).float()\n",
        "\n",
        "def fooling_rate(model, loader, attack):\n",
        "    model.eval()\n",
        "    fooled, total = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        preds_orig = preds_to_labels(model(x).detach())\n",
        "        x_adv = attack(model, x, y)\n",
        "        preds_adv = preds_to_labels(model(x_adv).detach())\n",
        "        batch_fooled = (preds_adv != preds_orig).any(dim=1)\n",
        "        fooled += batch_fooled.sum().item()\n",
        "        total += x.size(0)\n",
        "    return fooled / total"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}